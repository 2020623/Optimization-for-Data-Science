{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "10HCmNZ7ptig",
        "TpVmZOpBDoa4",
        "01atVGk6Doa_",
        "A905eVUuNBur"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Z6U-1BHzQl"
      },
      "source": [
        "Lorenzo Corrado - Federico Zanotti\n",
        "\n",
        "# Zeroth Order Methods for Adversarial Machine Learning\n",
        "### Optimization for Data Science Project\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEYtRzzfUJAU"
      },
      "source": [
        "## Import and Data preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ZOLjCk0cai"
      },
      "source": [
        "# Import the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Optimizer\n",
        "from keras.models import Model\n",
        "from scipy.special import softmax\n",
        "from scipy.optimize import minimize\n",
        "from scipy.special import softmax\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import gzip\n",
        "import urllib.request\n",
        "import time\n",
        "import warnings\n",
        "import os\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "# Remove warnings in output\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set seed\n",
        "np.random.seed([2021])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPNwi2m10can"
      },
      "source": [
        "# Download MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# Model/data parameters\n",
        "num_classes = 10\n",
        "input_shape = (784,)\n",
        "\n",
        "# Scale images in [0,1] range\n",
        "x_train = x_train.astype(\"float32\")/255\n",
        "x_test = x_test.astype(\"float32\")/255\n",
        "\n",
        "# Make sure images have shape (28,28,1)\n",
        "# x_train = np.expand_dims(x_train, -1)\n",
        "# x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "x_train = x_train.reshape((60000, 784))\n",
        "x_test = x_test.reshape((10000, 784))\n",
        "\n",
        "# Splitting training set in training and valid\n",
        "validation_size = 5000\n",
        "\n",
        "x_val = x_train[:validation_size]\n",
        "y_val = y_train[:validation_size]\n",
        "x_train = x_train[validation_size:]\n",
        "y_train = y_train[validation_size:]\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBqqabva0cao"
      },
      "source": [
        "# Define DNN architecture\n",
        "model = keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=input_shape))\n",
        "model.add(tf.keras.layers.Reshape((28,28,1), input_shape=input_shape))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(200, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(200, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dense(num_classes, name=\"last_dense\"))\n",
        "model.add(tf.keras.layers.Activation(\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvSiSVcQ1w1l"
      },
      "source": [
        "# Take the output of the last layer before the softmax operation\n",
        "dnn = Model(inputs=model.input, outputs=model.get_layer(\"last_dense\").output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zciAo4vY0Wb_"
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "## github link: https://github.com/IBM/ZOSVRG-BlackBox-Adv/tree/master/models\n",
        "## Loads the weights\n",
        "path = \"./mnist\"\n",
        "if os.path.isfile(path):\n",
        "  model.load_weights(path) \n",
        "\n",
        "else:\n",
        "  print(f\"file {path} does not exist\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10HCmNZ7ptig"
      },
      "source": [
        "## Utility Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN1yh4uiDoa1"
      },
      "source": [
        "# Definition of the objective function to be minimized #(FOR ALL THE SAMPLES)\n",
        "def F(x, y_true):\n",
        "  \"\"\"\n",
        "  Loss function for all the examples\n",
        "\n",
        "  Input:\n",
        "  - x: images\n",
        "  - y_true: true labels of the images\n",
        "\n",
        "  \"\"\"\n",
        "  f = dnn.predict(x)\n",
        "  f_yi = np.max(f*y_true, axis=1)\n",
        "  f_j = np.max(f*np.where(y_true == 1, -1e10, 1), axis=1)\n",
        "  \n",
        "  return np.mean(np.where(f_yi - f_j > 0, f_yi - f_j, 0))\n",
        "\n",
        "def F_Par(x, y_true):\n",
        "  \"\"\"\n",
        "  Loss function for only one example\n",
        "\n",
        "  Input:\n",
        "  - x: image\n",
        "  - y: true label of the image\n",
        "\n",
        "  \"\"\"\n",
        "  f = dnn.predict(x)\n",
        "  f_yi = np.max(f*y_true, axis=1)\n",
        "  f_j = np.max(f*np.where(y_true == 1, -1e10, 1), axis=1)\n",
        "\n",
        "  return np.where(f_yi-f_j > 0, f_yi-f_j, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opRJFT_7S3Z8"
      },
      "source": [
        "# Extract n images from the same class\n",
        "def extract_images(n, c):\n",
        "  \"\"\"\n",
        "  Extract some images of the same class\n",
        "\n",
        "  Input:\n",
        "  - n: number of images to extract\n",
        "  - c: label\n",
        "\n",
        "  \"\"\"\n",
        "  x_extr = np.copy(x_test[y_test.argmax(axis=1)==c][:n])\n",
        "  y_extr = np.copy(y_test[y_test.argmax(axis=1)==c][:n])\n",
        "  \n",
        "  return x_extr, y_extr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thqa7_Emp4va"
      },
      "source": [
        "def get_data(n, c):\n",
        "  \"\"\"\n",
        "\n",
        "  Get n images of same class \n",
        "\n",
        "  Input:\n",
        "  -n: sample size\n",
        "  -c: label of image\n",
        "\n",
        "  \"\"\"\n",
        "  img_in, y_true_in = extract_images(n,c)\n",
        "  x_ori = np.copy(img_in)\n",
        "  x = np.copy(x_ori)\n",
        "  return x, x_ori, y_true_in "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYVhZRt6wfzP"
      },
      "source": [
        "def stop_attack(x, y_true):\n",
        "  \"\"\" \n",
        "  Stopping criterion\n",
        "\n",
        "  Input: \n",
        "  - x: images\n",
        "  - y_true: true label of images\n",
        "\n",
        "  \"\"\"\n",
        "  success = dnn.predict(x).argmax(axis=1)\n",
        "  return sum(success==y_true.argmax(axis=1))==0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dN2N5Qy6-0r"
      },
      "source": [
        "def RandGradEst(x, y_true, v):\n",
        "  \"\"\"\n",
        "  Two-point (gaussian) random gradient estimator\n",
        "\n",
        "  Input:\n",
        "  - x: image\n",
        "  - y_true: true label of the image\n",
        "  - v: smoothing parameter \n",
        "  \"\"\"\n",
        "  u = np.random.standard_normal((1,d))\n",
        "  F_plus = F(x + v*u, y_true)\n",
        "  F_ = F(x, y_true)\n",
        "  \n",
        "  return (d/v)*(F_plus - F_)*u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWcMXu6iFZwx"
      },
      "source": [
        "def Avg_RandGradEst(x, y_true, q, v):\n",
        "  \"\"\"\n",
        "  Averaged (gaussian) random gradient estimator\n",
        "\n",
        "  Input:\n",
        "  - x: image\n",
        "  - y_true: true label of the image\n",
        "  - q: number of random directions\n",
        "  - v: smoothing parameter\n",
        "  \"\"\"\n",
        "  g = 0\n",
        "  u = np.random.standard_normal((q,d))\n",
        "  F_ = F(x, y_true)\n",
        "  for j in range(q):\n",
        "    F_plus = F(x + v*u[j], y_true)\n",
        "    g = g + (F_plus - F_)*u[j]\n",
        "\n",
        "  return (d/(v*q))*g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEuEQWPKr-0E"
      },
      "source": [
        "def CoordGradEst(x, y_true, mu):\n",
        "  \"\"\"\n",
        "  Coordinate-wise gradient estimator\n",
        "  \n",
        "  Input:\n",
        "  - x: images\n",
        "  - y_true: true labels of the images\n",
        "  - mu: smoothing parameter\n",
        "\n",
        "  \"\"\"\n",
        "  q = 0\n",
        "  for j in tqdm(range(d)):\n",
        "    F_plus = F(x + mu*e(j,d), y_true)\n",
        "    F_minus = F(x - mu*e(j,d), y_true)\n",
        "    diff = F_plus - F_minus\n",
        "    q = q + (diff)*e(j,d)\n",
        "   \n",
        "  return q/(2*mu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yshr05Pw_l8d"
      },
      "source": [
        "def attack_success_rate(x, y):\n",
        "  \"\"\"\n",
        "  Calculate in percentage the Attack Success Rate of x\n",
        "\n",
        "  Input:\n",
        "  - x: images\n",
        "  - y: true labels of images\n",
        "  \"\"\"\n",
        "  predicted=softmax(dnn.predict(x)).argmax(axis=1)\n",
        "  # print(predicted)\n",
        "  true_values=y.argmax(axis=1)\n",
        "  adversarial=len(predicted)-sum(predicted==true_values)\n",
        "  wrong_label=(adversarial/len(predicted))*100\n",
        "  return round(wrong_label,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePga3_-GgfYu"
      },
      "source": [
        "def plot_all(loss_ZSCG, loss_FZFW, loss_FZCGS, epochs, n, title=\"\",savefig=\"\"):\n",
        "  \"\"\"\n",
        "  Utility function to plot the loss of three algorithms\n",
        "  \n",
        "  Input:\n",
        "  - loss_ZSCG: loss of methods ZSCG\n",
        "  - loss_FZFW: loss of methods FZFW\n",
        "  - loss_FZSCG: loss of methods FZSCG\n",
        "  - epochs: number of iterations\n",
        "  - n: sample size\n",
        "\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,8))\n",
        "  plt.plot(loss_ZSCG, label=f\"ZSCG with {n} examples\")\n",
        "  plt.plot(loss_FZFW, label=f\"FZFW with {n} examples\")\n",
        "  plt.plot(loss_FZCGS, label=f\"FZCGS with {n} examples\")\n",
        "  plt.grid(\"on\")\n",
        "  plt.legend()\n",
        "  plt.xticks(np.arange(0,epochs+10,10))\n",
        "  plt.xlabel(\"# iterations\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  if title!=\"\":\n",
        "    plt.title(title)\n",
        "  if savefig != \"\":\n",
        "    plt.savefig(savefig)\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LEJ7bvxtiMv"
      },
      "source": [
        "def nice_table(x_mod, y_true, param1, param2):\n",
        "  \"\"\"\n",
        "  Utility function to visualize a nice plot for the grid search of Hyperparams\n",
        "  \n",
        "  Input:\n",
        "  - x_mod: images perturbated\n",
        "  - y_true: true label of images\n",
        "  - param1: (name of param1, value of param1)\n",
        "  - param1: (name of param2, value of param2)\n",
        "  \"\"\"\n",
        "  param1_list = param1[1]\n",
        "  param2_list = param2[1]\n",
        "  j=0\n",
        "  i=0\n",
        "  t= PrettyTable([param1[0], param2[0], \"ASR (%)\"])\n",
        "  for el in x_mod:\n",
        "    asr=attack_success_rate(el, y_true)\n",
        "    if i==len(param2_list):\n",
        "      i=0\n",
        "      p2 = param2_list[i]\n",
        "      j +=1\n",
        "      p1=param1_list[j]\n",
        "    else:\n",
        "      p2 = param2_list[i]\n",
        "      p1=param1_list[j]\n",
        "    i +=1\n",
        "    \n",
        "    t.add_row([f\" {p1}\", f\" {p2}\", asr])\n",
        "  return t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpVmZOpBDoa4"
      },
      "source": [
        "## Algorithm 1. Zeroth-Order Stochastic Conditional Gradient Method (ZSCG)\n",
        "\n",
        "K. Balasubramanian et al., 2018."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey9R0yUtPU4W"
      },
      "source": [
        "def Avg_RandGradEst_Par(x, y_true, q, v, d):\n",
        "  \"\"\"\n",
        "  Averaged (gaussian) random gradient estimator in parallel\n",
        "\n",
        "  Input:\n",
        "  - x: image\n",
        "  - y_true: true label of the image\n",
        "  - q: number of random directions\n",
        "  - v: smoothing parameter\n",
        "  \"\"\"\n",
        "  g = 0\n",
        "  u = np.random.standard_normal((q,d))\n",
        "  x_par_plus = np.array([x + v*u[j] for j in range(q)]).reshape((q,d))\n",
        "  diff = F_Par(x_par_plus, y_true) - F(x, y_true)\n",
        "\n",
        "  for j in range(q):\n",
        "    g = g + (diff[j]/v) * u[j] \n",
        "  \n",
        "  return (d/(q*v))*g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-A6eK7loU5O"
      },
      "source": [
        "def ZSCG(N, d, s, m_k, x, y_true_in,v=-1,alpha=-1, B=1,verbose=True, clip=False):\n",
        "  \"\"\"\n",
        "\n",
        "  Zeroth-Order Stochastic Gradient Method\n",
        "\n",
        "  Input:\n",
        "  - N: number of epochs\n",
        "  - d: dimension of data\n",
        "  - s: distorsion\n",
        "  - x: images\n",
        "  - y_true_in: true label of images\n",
        "  - v: smoothing parameter \n",
        "  - alpha: step size\n",
        "  - B: parameter of convergence theory\n",
        "  - verbose: True/False for printing computations\n",
        "  - clip: True/False activate clipping\n",
        "  \n",
        "  \"\"\"\n",
        "  if v==-1:\n",
        "    v = np.sqrt(2/(N*(d+3)**3))\n",
        "  if alpha==-1:\n",
        "    alpha = 1/np.sqrt(N)\n",
        "\n",
        "  x_ori=np.copy(x)\n",
        "  loss_ZSCG = []\n",
        "  perturbations = []\n",
        "  loss_ZSCG.append(F(x, y_true_in))\n",
        "  if verbose:\n",
        "    print(\"Epoch:\", 0, \"Loss:\", F(x_ori, y_true_in), \"Distortion:\", np.max(np.abs(x-x_ori)))\n",
        "  for k in range(N):\n",
        "      \n",
        "    # Get the gradient estimate\n",
        "    v_k = 0\n",
        "    for i in tqdm(range(x.shape[0]), disable= not verbose):\n",
        "      v_k = v_k + Avg_RandGradEst_Par(x[i:i+1], y_true_in[i:i+1], m_k, v, d)    \n",
        "    v_k = (1/n)*v_k\n",
        "\n",
        "    x_k = -s * np.sign(v_k) + x_ori # Solve the LMO\n",
        "    x = (1 - alpha)*x+ alpha*x_k\n",
        "    if clip:\n",
        "      x= x_ori + np.clip((x-x_ori), 0, 1)\n",
        "\n",
        "    perturbations.append(x)\n",
        "    loss_ZSCG.append(F(x, y_true_in))\n",
        "\n",
        "    if verbose:\n",
        "      print(\"-\"*100)\n",
        "      print(\"Epoch:\", k+1, \"Loss:\", loss_ZSCG[k], \"Distortion:\", np.round(np.max(np.abs(x-x_ori)),5), \"Elapsed Time:\")\n",
        "\n",
        "    if stop_attack(x, y_true_in):\n",
        "      print(\"Attack successful! stopping computation...\")\n",
        "      return loss_ZSCG, x\n",
        "\n",
        "  ZSCG_x_perturbated = x\n",
        "\n",
        "  print(\"ZSCG Final loss = \", loss_ZSCG[-1])\n",
        "  return loss_ZSCG, ZSCG_x_perturbated, perturbations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01atVGk6Doa_"
      },
      "source": [
        "## Algorithm 2. Faster Zeroth-Order Frank-Wolfe Method (FZFW)\n",
        "Gao et al., 2020."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z09tgnWpsPJG"
      },
      "source": [
        "def e(i, d):\n",
        "  \"\"\"\n",
        "  Orthogonal basis vector\n",
        "\n",
        "  Input:\n",
        "  - i: index\n",
        "  - d: dimensions\n",
        "  \n",
        "  \"\"\"\n",
        "  ei = np.zeros(d)\n",
        "  ei[i] = 1\n",
        "  return ei"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gjXRr8DuiaW"
      },
      "source": [
        "def CoordGradEst_Par(x, y_true, mu,d):\n",
        "  \"\"\"\n",
        "  Coordinate-wise gradient estimator in parallel\n",
        "\n",
        "  Input:\n",
        "  - x: image\n",
        "  - y_true: true label of the image\n",
        "  - mu: smoothing parameter\n",
        "  \n",
        "  \"\"\"\n",
        "  x_par_plus = np.array([x + mu*e(j,d) for j in range(d)]).reshape(d,d)\n",
        "  x_par_minus = np.array([x - mu*e(j,d) for j in range(d)]).reshape(d,d)\n",
        "  diff = F_Par(x_par_plus, y_true) - F_Par(x_par_minus, y_true)\n",
        "  \n",
        "  q = 0\n",
        "  for j in range(d):\n",
        "    q = q + (diff[j])*(e(j,d)) \n",
        "    \n",
        "  return (1/(2*mu))*q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTs88TOUqZc5"
      },
      "source": [
        "def FZFW(K,d,n,s,gamma, mu,x,y_true_in, verbose=True, clip=False): \n",
        "  \"\"\"\n",
        "  Faster Zeroth-Order Frank-Wolfe Method\n",
        "  \n",
        "  Input:\n",
        "  - K: number of epochs\n",
        "  - d: dimension of data\n",
        "  - n: sample size\n",
        "  - s: distorsion\n",
        "  - gamma: step size \n",
        "  - mu: smoothing parameter \n",
        "  - x: images\n",
        "  - y_true_in: true label of images\n",
        "  - verbose: True/False for printing computations\n",
        "  - clip: True/False activate clipping\n",
        "  \n",
        "  \"\"\"\n",
        "  s_1=n\n",
        "  q = s_2 = int(np.sqrt(n))\n",
        "  if gamma==-1:\n",
        "    gamma = 1/np.sqrt(K)\n",
        "  if mu==-1:\n",
        "    mu = 1/np.sqrt(d*K)\n",
        "  x_ori=np.copy(x)\n",
        "\n",
        "\n",
        "  loss_FZFW = []\n",
        "  perturbations=[]\n",
        "  loss_FZFW.append(F(x_ori, y_true_in))\n",
        "  if verbose:\n",
        "    print(\"Epoch:\", 0, \"Loss:\", F(x_ori, y_true_in), \"Distortion:\", np.max(np.abs(x-x_ori)))\n",
        "    print(\"-\"*100)\n",
        "\n",
        "\n",
        "  for k in range(K):\n",
        "    if (k % q == 0):\n",
        "\n",
        "      v_k = 0\n",
        "      for i in tqdm(range(s_1), disable= not verbose):\n",
        "        v_k = v_k + CoordGradEst_Par(x[i:i+1], y_true_in[i:i+1], mu,d)\n",
        "      v_k=v_k/s_1\n",
        "      v_k_1 = v_k\n",
        "\n",
        "    else:\n",
        "\n",
        "\n",
        "\n",
        "      v_k = 0\n",
        "      s2_idx = np.random.randint(0, n, s_2) \n",
        "\n",
        "      for idx in tqdm(s2_idx,  disable= not verbose):\n",
        "        v_k = v_k + CoordGradEst_Par(x[idx:idx+1], y_true_in[idx:idx+1], mu,d) - CoordGradEst_Par(x_k_1[idx:idx+1], y_true_in[idx:idx+1], mu,d) + v_k_1\n",
        "      v_k = (1/s_2) * v_k\n",
        "      v_k_1 = v_k\n",
        "\n",
        "\n",
        "\n",
        "    x_k_1 = np.copy(x)\n",
        "    u_k = -s * np.sign(v_k) + x_ori # Solve the LMO\n",
        "    d_k = u_k - x\n",
        "    x = x + gamma*d_k\n",
        "\n",
        "\n",
        "    if clip:\n",
        "      x= x_ori + np.clip((x-x_ori), 0, 1)\n",
        "    \n",
        "    perturbations.append(x)\n",
        "    loss_FZFW.append(F(x, y_true_in))\n",
        "\n",
        "    if verbose:\n",
        "      print(\"Epoch:\", k+1, \"Loss:\", loss_FZFW[k+1], \"Distortion:\", np.round(np.max(np.abs(x-x_ori)),5))\n",
        "      print(\"-\"*100)\n",
        "\n",
        "    if stop_attack(x, y_true_in):\n",
        "      print(\"Attack successful! stopping computation...\")\n",
        "      return loss_FZFW, x\n",
        "    \n",
        "\n",
        " \n",
        "  FZFW_x_perturbated = x\n",
        "\n",
        "  print(\"FZFW Final loss = \", loss_FZFW[-1])\n",
        "\n",
        "  return loss_FZFW, FZFW_x_perturbated, perturbations\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A905eVUuNBur"
      },
      "source": [
        "## Algorithm 3. Faster Zeroth-Order Conditional Gradient Sliding Method (FZCGS)\n",
        "\n",
        "Gao et al., 2020."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPLEWOo3n7wC"
      },
      "source": [
        "def CondG(g, u, gamma, eta, x_ori, s, d):\n",
        "  \"\"\"\n",
        "  Conditional Gradient Sliding Algorithm\n",
        "  \n",
        "  Input:\n",
        "  - g: gradient\n",
        "  - u: images perturbated\n",
        "  - eta: threshold parameter\n",
        "  - x_ori: images without perturbations\n",
        "  - s: distorsion\n",
        "  - d: dimension of images\n",
        "\n",
        "  \"\"\"\n",
        "  t=1\n",
        "  u_t=u\n",
        "  \n",
        "  while (True):\n",
        "    grad = g + (1/gamma)*(u_t-u)\n",
        "    v = -s * np.sign(g) + x_ori\n",
        "    V = np.dot(grad, (u_t-v).T)\n",
        "    if (np.max(V) <= eta):\n",
        "      return u_t\n",
        "    if t==100:\n",
        "      return u_t\n",
        "\n",
        "    else:\n",
        "      \n",
        "      d = v-u_t\n",
        "      alpha = np.dot((1/gamma) * (u-u_t)-g, d.T) / ((1/gamma)*np.dot(d, d.T))\n",
        "      alpha = np.min(alpha) \n",
        "      if (alpha > 1):\n",
        "        alpha = 1     \n",
        "      u_t = (1-alpha)*u_t + alpha*v\n",
        "      t = t+1\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcjEpu8VnnJq"
      },
      "source": [
        "def FZCGS(K,d,n,s,gamma, mu, eta, x,y_true_in, verbose=True, clip=False):\n",
        "  \"\"\"\n",
        "  Faster Zeroth-Order Conditional Gradient Method\n",
        "  \n",
        "  Input:\n",
        "  - K: number of epochs\n",
        "  - d: dimension of data\n",
        "  - n: sample size\n",
        "  - s: distorsion\n",
        "  - gamma: step size \n",
        "  - mu: smoothing parameter \n",
        "  - eta: treshold parameter \n",
        "  - x: images\n",
        "  - y_true_in: true label of images\n",
        "  - verbose: True/False for printing computations\n",
        "  - clip: True/False activate clipping\n",
        "  \n",
        "  \"\"\"\n",
        "  s_1 = n\n",
        "  q = s_2 = int(np.sqrt(n))\n",
        "  if gamma==-1:\n",
        "    gamma = 1/np.sqrt(K)\n",
        "  if mu==-1:\n",
        "    mu = 1/np.sqrt(d*K)\n",
        "  if eta==-1:\n",
        "    eta = 1/K\n",
        "  x_ori=np.copy(x)\n",
        "\n",
        "\n",
        "  loss_FZCGS = []\n",
        "  perturbations=[]\n",
        "  loss_FZCGS.append(F(x_ori, y_true_in))\n",
        "  if verbose:\n",
        "    print(\"Epoch:\", 0, \"Loss:\", F(x_ori, y_true_in), \"Distortion:\", np.max(np.abs(x-x_ori)))\n",
        "    print(\"-\"*100)\n",
        "\n",
        "  for k in range(K):\n",
        "    \n",
        "    if (k % q == 0):\n",
        "      \n",
        "\n",
        "      v_k = 0\n",
        "      for i in tqdm(range(s_1), disable=not verbose):\n",
        "        v_k = v_k + CoordGradEst_Par(x[i:i+1], y_true_in[i:i+1], mu,d)\n",
        "      v_k=v_k/s_1\n",
        "      v_k_1 = v_k\n",
        "\n",
        "    else:\n",
        "    \n",
        "\n",
        "      v_k = 0\n",
        "      s2_idx = np.random.randint(0, n, s_2) \n",
        "    \n",
        "      for idx in tqdm(s2_idx,  disable= not verbose):\n",
        "        # idx = np.random.randint(0,n)\n",
        "        v_k = v_k + CoordGradEst_Par(x[idx:idx+1], y_true_in[idx:idx+1], mu, d) - CoordGradEst_Par(x_k_1[idx:idx+1], y_true_in[idx:idx+1], mu,d) + v_k_1\n",
        "      v_k = (1/s_2) * v_k\n",
        "      v_k_1 = v_k\n",
        "\n",
        "\n",
        "    x_k_1 = np.copy(x)\n",
        "    x = CondG(v_k, x, gamma, eta, x_ori, s, d) # Cong procedure\n",
        "\n",
        "\n",
        "    if clip:\n",
        "      x= x_ori + np.clip((x-x_ori), 0, 1)\n",
        "    perturbations.append(x)\n",
        "    loss_FZCGS.append(F(x, y_true_in))\n",
        "    if verbose:\n",
        "      print(\"-\"*100)\n",
        "      print(\"Epoch:\", k+1, \"Loss:\", loss_FZCGS[k], \"Distortion:\", np.round(np.max(np.abs(x-x_ori)),5))\n",
        "    if stop_attack(x, y_true_in):\n",
        "      print(\"Attack successful! stopping computation...\")\n",
        "      return loss_FZCGS, x\n",
        "    \n",
        "\n",
        "\n",
        "  FZCGS_x_perturbated = x\n",
        "\n",
        "  print(\"FZCGS Final loss = \", loss_FZCGS[-1])\n",
        "\n",
        "  return loss_FZCGS, FZCGS_x_perturbated, perturbations"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}